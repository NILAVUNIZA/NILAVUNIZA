{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1a5efaBs4KSa5LXHF5uIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NILAVUNIZA/NILAVUNIZA/blob/main/CMIP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsVdPdD8LrkK",
        "outputId": "e0a5728f-a7db-4152-d775-2a36c5abd3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.3.1)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.6.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2\n"
          ]
        }
      ],
      "source": [
        "pip install netCDF4 pandas xarray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Open the .nc file\n",
        "nc_file = Dataset('/content/CMIP5.label.type.DJF.1863_2003.nc', 'r')\n",
        "\n",
        "# Check available variables\n",
        "print(nc_file.variables.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuBK7KTIMjZZ",
        "outputId": "40692b8f-0cde-4a0e-8564-aed8de03a438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lon', 'lat', 'lev', 'time', 'pr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "124c04da",
        "outputId": "c8cf5805-490c-4df0-859c-c45711e58f70"
      },
      "source": [
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the NetCDF file\n",
        "nc_file = Dataset('/content/CMIP5.label.type.DJF.1863_2003.nc', 'r')\n",
        "\n",
        "# Step 2: Extract variable data\n",
        "lon = nc_file.variables['lon'][:]\n",
        "lat = nc_file.variables['lat'][:]\n",
        "time = nc_file.variables['time'][:]\n",
        "pr = nc_file.variables['pr'][:]\n",
        "\n",
        "# Close the NetCDF file\n",
        "nc_file.close()\n",
        "\n",
        "# Print the shape of pr for debugging\n",
        "print(\"Shape of pr:\", pr.shape)\n",
        "\n",
        "\n",
        "# Step 3: Create a Pandas DataFrame\n",
        "# We need to flatten the data and create a DataFrame\n",
        "# This assumes that 'pr' is structured as (time, level, lat, lon) or similar\n",
        "# Based on the shape (877, 3, 1, 1), it appears to be (time, level, lat, lon) with single lat/lon values\n",
        "n_time, n_level, n_lat, n_lon = pr.shape\n",
        "\n",
        "# Create a meshgrid for lat and lon - given shape is 1,1, we can use the single values\n",
        "# If lat and lon had more values, we would need a meshgrid based on their actual values\n",
        "# For shape (877, 3, 1, 1), lat and lon likely correspond to single fixed points.\n",
        "# We will repeat the single lat/lon values for each time and level.\n",
        "\n",
        "# Flatten the data while preserving the time and level dimensions for now\n",
        "pr_reshaped = pr.reshape(n_time, n_level, n_lat * n_lon)\n",
        "\n",
        "\n",
        "# Now flatten across time and level, repeating lat/lon for each entry\n",
        "time_flat = np.repeat(time, n_level * n_lat * n_lon)\n",
        "level_flat = np.tile(np.repeat(np.arange(n_level), n_lat * n_lon), n_time) # Assuming the 2nd dim is level\n",
        "lat_flat = np.tile(np.repeat(lat, n_lon), n_time * n_level)\n",
        "lon_flat = np.tile(lon, n_time * n_level * n_lat)\n",
        "\n",
        "pr_flat = pr_reshaped.flatten()\n",
        "\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'time': time_flat,\n",
        "    'level': level_flat, # Include the level dimension\n",
        "    'lat': lat_flat,\n",
        "    'lon': lon_flat,\n",
        "    'pr': pr_flat\n",
        "})\n",
        "\n",
        "# Convert time to datetime objects (optional, depending on your needs)\n",
        "# You might need to adjust the unit and calendar based on the NetCDF file's time variable attributes\n",
        "# Example: assuming time is in days since a reference date\n",
        "# df['time'] = pd.to_datetime(df['time'], unit='D', origin='1863-01-01')\n",
        "\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "df.to_csv('output.csv', index=False)\n",
        "\n",
        "print(\"Conversion complete. Data saved to output.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of pr: (877, 3, 1, 1)\n",
            "Conversion complete. Data saved to output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "403ed379",
        "outputId": "139ea371-e6d1-47b3-cfcc-a774a944b237"
      },
      "source": [
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the NetCDF file\n",
        "nc_file = Dataset('/content/CMIP5.label.nino34.12mn_3mv.1863_2003.nc', 'r')\n",
        "\n",
        "# Step 2: Extract variable data\n",
        "lon = nc_file.variables['lon'][:]\n",
        "lat = nc_file.variables['lat'][:]\n",
        "time = nc_file.variables['time'][:]\n",
        "pr = nc_file.variables['pr'][:]\n",
        "\n",
        "# Close the NetCDF file\n",
        "nc_file.close()\n",
        "\n",
        "# Print the shape of pr for debugging\n",
        "print(\"Shape of pr:\", pr.shape)\n",
        "\n",
        "# Step 3: Create a Pandas DataFrame\n",
        "# We need to flatten the data and create a DataFrame\n",
        "# Based on the shape (877, 3, 1, 1) from the previous file,\n",
        "# we will assume a similar structure (time, level, lat, lon)\n",
        "n_time, n_level, n_lat, n_lon = pr.shape\n",
        "\n",
        "# Flatten the data while preserving the time and level dimensions\n",
        "pr_reshaped = pr.reshape(n_time, n_level, n_lat * n_lon)\n",
        "\n",
        "# Flatten across time and level, repeating lat/lon for each entry\n",
        "time_flat = np.repeat(time, n_level * n_lat * n_lon)\n",
        "level_flat = np.tile(np.repeat(np.arange(n_level), n_lat * n_lon), n_time)\n",
        "lat_flat = np.tile(np.repeat(lat, n_lon), n_time * n_level)\n",
        "lon_flat = np.tile(lon, n_time * n_level * n_lat)\n",
        "\n",
        "pr_flat = pr_reshaped.flatten()\n",
        "\n",
        "# Create the DataFrame\n",
        "df_nino = pd.DataFrame({\n",
        "    'time': time_flat,\n",
        "    'level': level_flat,\n",
        "    'lat': lat_flat,\n",
        "    'lon': lon_flat,\n",
        "    'pr': pr_flat\n",
        "})\n",
        "\n",
        "# Convert time to datetime objects (optional, depending on your needs)\n",
        "# You might need to adjust the unit and calendar based on the NetCDF file's time variable attributes\n",
        "# Example: assuming time is in days since a reference date\n",
        "# df_nino['time'] = pd.to_datetime(df_nino['time'], unit='D', origin='1863-01-01')\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "df_nino.to_csv('output_nino34.csv', index=False)\n",
        "\n",
        "print(\"Conversion complete. Data saved to output_nino34.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of pr: (2961, 12, 1, 1)\n",
            "Conversion complete. Data saved to output_nino34.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Open the .nc file\n",
        "nc_file = Dataset('/content/CMIP5.label.nino34.12mn_3mv.1863_2003.nc', 'r')\n",
        "\n",
        "# Check available variables\n",
        "print(nc_file.variables.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi12gvttSseE",
        "outputId": "1830974a-3ddc-473e-a328-7066a8507005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lon', 'lat', 'lev', 'time', 'pr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Open the .nc file\n",
        "nc_file = Dataset('/content/CMIP5.label.nino34.12mn_2mv.1863_2003.nc', 'r')\n",
        "\n",
        "# Check available variables\n",
        "print(nc_file.variables.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS0uFRunStnx",
        "outputId": "c83ebc95-1793-4bd1-d9a5-90b20fa1ad96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lon', 'lat', 'lev', 'time', 'pr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff7dc7ae",
        "outputId": "15c22824-7229-4f48-9d30-e26f1ca2c294"
      },
      "source": [
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the NetCDF file\n",
        "nc_file = Dataset('/content/CMIP5.label.nino34.12mn_2mv.1863_2003.nc', 'r')\n",
        "\n",
        "# Step 2: Extract variable data\n",
        "lon = nc_file.variables['lon'][:]\n",
        "lat = nc_file.variables['lat'][:]\n",
        "time = nc_file.variables['time'][:]\n",
        "pr = nc_file.variables['pr'][:]\n",
        "\n",
        "# Close the NetCDF file\n",
        "nc_file.close()\n",
        "\n",
        "# Print the shape of pr for debugging\n",
        "print(\"Shape of pr:\", pr.shape)\n",
        "\n",
        "# Step 3: Create a Pandas DataFrame\n",
        "# We need to flatten the data and create a DataFrame\n",
        "# Based on the shape (time, level, lat, lon) observed in previous files,\n",
        "# we will assume a similar structure.\n",
        "n_time, n_level, n_lat, n_lon = pr.shape\n",
        "\n",
        "# Flatten the data while preserving the time and level dimensions\n",
        "pr_reshaped = pr.reshape(n_time, n_level, n_lat * n_lon)\n",
        "\n",
        "# Flatten across time and level, repeating lat/lon for each entry\n",
        "time_flat = np.repeat(time, n_level * n_lat * n_lon)\n",
        "level_flat = np.tile(np.repeat(np.arange(n_level), n_lat * n_lon), n_time)\n",
        "lat_flat = np.tile(np.repeat(lat, n_lon), n_time * n_level)\n",
        "lon_flat = np.tile(lon, n_time * n_level * n_lat)\n",
        "\n",
        "pr_flat = pr_reshaped.flatten()\n",
        "\n",
        "# Create the DataFrame\n",
        "df_nino_2mv = pd.DataFrame({\n",
        "    'time': time_flat,\n",
        "    'level': level_flat,\n",
        "    'lat': lat_flat,\n",
        "    'lon': lon_flat,\n",
        "    'pr': pr_flat\n",
        "})\n",
        "\n",
        "# Convert time to datetime objects (optional, depending on your needs)\n",
        "# You might need to adjust the unit and calendar based on the NetCDF file's time variable attributes\n",
        "# Example: assuming time is in days since a reference date\n",
        "# df_nino_2mv['time'] = pd.to_datetime(df_nino_2mv['time'], unit='D', origin='1863-01-01')\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "df_nino_2mv.to_csv('output_nino34_2mv.csv', index=False)\n",
        "\n",
        "print(\"Conversion complete. Data saved to output_nino34_2mv.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of pr: (2961, 12, 1, 1)\n",
            "Conversion complete. Data saved to output_nino34_2mv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-i3bk-8IStsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Open the .nc file\n",
        "nc_file = Dataset('/content/CMIP5.input.type.NDJ.1861_2001.nc', 'r')\n",
        "\n",
        "# Check available variables\n",
        "print(nc_file.variables.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g622BmTCStpj",
        "outputId": "2d913318-cd0d-499e-8d0a-702b7a8a4487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lon', 'lat', 'lev', 'time', 'sst', 't300'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fc76489",
        "outputId": "f3d0fa21-dc63-48cb-bac4-cfc512a689d1"
      },
      "source": [
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the NetCDF file\n",
        "nc_file = Dataset('/content/CMIP5.input.type.NDJ.1861_2001.nc', 'r')\n",
        "\n",
        "# Step 2: Extract variable data\n",
        "lon = nc_file.variables['lon'][:]\n",
        "lat = nc_file.variables['lat'][:]\n",
        "time = nc_file.variables['time'][:]\n",
        "level = nc_file.variables['lev'][:] # Extract the level variable\n",
        "sst = nc_file.variables['sst'][:]\n",
        "t300 = nc_file.variables['t300'][:]\n",
        "\\\n",
        "\n",
        "\n",
        "# Close the NetCDF file\n",
        "nc_file.close()\n",
        "\n",
        "# Print the shapes for debugging\n",
        "print(\"Shape of sst:\", sst.shape)\n",
        "print(\"Shape of t300:\", t300.shape)\n",
        "\n",
        "\n",
        "# Step 3: Create a Pandas DataFrame\n",
        "# Assuming the variables 'sst' and 't300' have a structure like (time, level, lat, lon)\n",
        "n_time, n_level, n_lat, n_lon = sst.shape # Use sst shape to get dimensions\n",
        "\n",
        "# Flatten the data while preserving time and level dimensions\n",
        "sst_reshaped = sst.reshape(n_time, n_level, n_lat * n_lon)\n",
        "t300_reshaped = t300.reshape(n_time, n_level, n_lat * n_lon)\n",
        "\n",
        "\n",
        "# Now flatten across time and level, repeating lat/lon for each entry\n",
        "time_flat = np.repeat(time, n_level * n_lat * n_lon)\n",
        "# Repeat level values for each time and lat/lon combination\n",
        "level_flat = np.tile(np.repeat(level, n_lat * n_lon), n_time)\n",
        "lat_flat = np.tile(np.repeat(lat, n_lon), n_time * n_level)\n",
        "lon_flat = np.tile(lon, n_time * n_level * n_lat)\n",
        "\n",
        "sst_flat = sst_reshaped.flatten()\n",
        "t300_flat = t300_reshaped.flatten()\n",
        "\n",
        "\n",
        "# Create the DataFrame\n",
        "df_input = pd.DataFrame({\n",
        "    'time': time_flat,\n",
        "    'level': level_flat,\n",
        "    'lat': lat_flat,\n",
        "    'lon': lon_flat,\n",
        "    'sst': sst_flat,\n",
        "    't300': t300_flat\n",
        "})\n",
        "\n",
        "# Convert time to datetime objects (optional, depending on your needs)\n",
        "# You might need to adjust the unit and calendar based on the NetCDF file's time variable attributes\n",
        "# Example: assuming time is in days since a reference date\n",
        "# df_input['time'] = pd.to_datetime(df_input['time'], unit='D', origin='1861-01-01')\n",
        "\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "df_input.to_csv('output_input.csv', index=False)\n",
        "\n",
        "print(\"Conversion complete. Data saved to output_input.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of sst: (877, 3, 24, 72)\n",
            "Shape of t300: (877, 3, 24, 72)\n",
            "Conversion complete. Data saved to output_input.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNWOU9IBStl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyR7iciYStiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMReTl2dStfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ef3UIeohStdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QLBmGzo_StRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOUCZFFwStOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qrkOUrsVStL4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}